{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PDF Text extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import fitz\n",
    "import geocoder\n",
    "import pymysql\n",
    "import fitz\n",
    "from openai import OpenAI\n",
    "from settings import *\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAEMATOLOGY\n",
      "COMPLETE BLOOD COUNT (CBC)\n",
      "TEST\n",
      "VALUE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    document = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(len(document)):\n",
    "        page = document[page_num]\n",
    "        text += page.get_text()\n",
    "    document.close()\n",
    "    return text.strip()\n",
    "\n",
    "pdf_text = extract_text_from_pdf(\"cbc-report-format.pdf\")\n",
    "print(pdf_text[:50])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quadrant code ##NOT USED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from qdrant_client import models, QdrantClient\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# # Initialize the encoder and Qdrant client\n",
    "# encoder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "# client = QdrantClient(\":memory:\")  # For in-memory use; replace with cluster host info for persistent storage\n",
    "\n",
    "\n",
    "# collection_name = \"medical_reports\"\n",
    "# client.create_collection(\n",
    "#     collection_name=collection_name,\n",
    "#     vectors_config=models.VectorParams(\n",
    "#         size=encoder.get_sentence_embedding_dimension(),  # Vector size is defined by the encoder\n",
    "#         distance=models.Distance.COSINE,  # Use cosine similarity\n",
    "#     ),\n",
    "# )\n",
    "\n",
    "# def chunk_text(text, chunk_size=500):\n",
    "#     return [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "\n",
    "# chunks = chunk_text(pdf_text)\n",
    "\n",
    "# client.upload_points(\n",
    "#     collection_name=collection_name,\n",
    "#     points=[\n",
    "#         models.PointStruct(\n",
    "#             id=idx,\n",
    "#             vector=encoder.encode(chunk).tolist(),\n",
    "#             payload={\"chunk\": chunk}\n",
    "#         )\n",
    "#         for idx, chunk in enumerate(chunks)\n",
    "#     ],\n",
    "# )\n",
    "\n",
    "# print(f\"Stored {len(chunks)} chunks in Qdrant.\")\n",
    "\n",
    "\n",
    "# def query_relevant_chunks(query_text, top_k=5):\n",
    "#     query_vector = encoder.encode(query_text).tolist()\n",
    "#     hits = client.query_points(\n",
    "#         collection_name=collection_name,\n",
    "#         query=query_vector,\n",
    "#         limit=top_k,\n",
    "#     ).points\n",
    "#     return [hit.payload[\"chunk\"] for hit in hits]\n",
    "\n",
    "# query = \"summarize the medical findings\"\n",
    "# relevant_chunks = query_relevant_chunks(query)\n",
    "\n",
    "# print(\"Relevant chunks for summarization:\")\n",
    "# for chunk in relevant_chunks:\n",
    "#     print(chunk[:200], \"...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from openai import OpenAI\n",
    "# from settings import *\n",
    "# import os\n",
    "\n",
    "# generation_model_name: str\n",
    "# temperature: float = 0.9\n",
    "# top_p = 0.9\n",
    "# max_tokens: int = 2048\n",
    "# stream: bool = True\n",
    "# llm_name: str = \"Meta-Llama\"\n",
    "\n",
    "# monster_client = OpenAI(\n",
    "#     base_url=\"https://llm.monsterapi.ai/v1/\",\n",
    "#     api_key=str(MONSTER_API_KEY)\n",
    "# )\n",
    "\n",
    "# monster_ai_model_name = {\n",
    "#     \"Google-Gemma\": \"google/gemma-2-9b-it\",\n",
    "#     \"Mistral\": \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "#     \"Microsoft-Phi\": \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "#     \"Meta-Llama\": \"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "# }\n",
    "\n",
    "# # Context and Summarization Prompt\n",
    "# message = [\n",
    "#     {\"role\": \"system\", \"content\": \"You are an AI assistant skilled in summarizing complex medical reports.\"},\n",
    "#     {\"role\": \"user\", \"content\": f\"Summarize the following medical report in simple terms. Focus on the key findings, diagnoses, and recommendations. Report text:\\n\\n{pdf_text}\"}\n",
    "# ]\n",
    "\n",
    "# # Generate Summary\n",
    "# response = monster_client.chat.completions.create(\n",
    "#     model=monster_ai_model_name[llm_name],\n",
    "#     messages=message,\n",
    "#     temperature=temperature,\n",
    "#     top_p=top_p,\n",
    "#     max_tokens=max_tokens,\n",
    "#     stream=stream\n",
    "# )\n",
    "\n",
    "# # Collect Generated Text\n",
    "# generated_text = \"\"\n",
    "# for chunk in response:\n",
    "#     if chunk.choices[0].delta.content is not None:\n",
    "#         generated_text += chunk.choices[0].delta.content\n",
    "\n",
    "# print(\"Generated Summary:\")\n",
    "# print(generated_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'message' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 75\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# Launch the Interface\u001b[39;00m\n\u001b[1;32m     71\u001b[0m interface\u001b[38;5;241m.\u001b[39mlaunch()\n\u001b[1;32m     73\u001b[0m response \u001b[38;5;241m=\u001b[39m monster_client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     74\u001b[0m     model\u001b[38;5;241m=\u001b[39mmonster_ai_model_name[llm_name],\n\u001b[0;32m---> 75\u001b[0m     messages\u001b[38;5;241m=\u001b[39m\u001b[43mmessage\u001b[49m,\n\u001b[1;32m     76\u001b[0m     temperature\u001b[38;5;241m=\u001b[39mtemperature,\n\u001b[1;32m     77\u001b[0m     top_p\u001b[38;5;241m=\u001b[39mtop_p,\n\u001b[1;32m     78\u001b[0m     max_tokens\u001b[38;5;241m=\u001b[39mmax_tokens,\n\u001b[1;32m     79\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream\n\u001b[1;32m     80\u001b[0m )\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI Response:\u001b[39m\u001b[38;5;124m\"\u001b[39m, response)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'message' is not defined"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Exception in thread Thread-24 (_do_normal_analytics_request):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/httpcore/_exceptions.py\", line 10, in map_exceptions\n",
      "Thread-22 (_do_normal_analytics_request):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/httpcore/_exceptions.py\", line 10, in map_exceptions\n",
      "    yield\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/httpcore/_backends/sync.py\", line 168, in start_tls\n",
      "    yield\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/httpcore/_backends/sync.py\", line 168, in start_tls\n",
      "    raise exc\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/httpcore/_backends/sync.py\", line 163, in start_tls\n",
      "    raise exc\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/httpcore/_backends/sync.py\", line 163, in start_tls\n",
      "    sock = ssl_context.wrap_socket(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/ssl.py\", line 517, in wrap_socket\n",
      "    sock = ssl_context.wrap_socket(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/ssl.py\", line 517, in wrap_socket\n",
      "    return self.sslsocket_class._create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/ssl.py\", line 1108, in _create\n",
      "    return self.sslsocket_class._create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/ssl.py\", line 1108, in _create\n",
      "    self.do_handshake()\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/ssl.py\", line 1383, in do_handshake\n",
      "    self.do_handshake()\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/ssl.py\", line 1383, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "TimeoutError: _ssl.c:989: The handshake operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/httpx/_transports/default.py\", line 67, in map_httpcore_exceptions\n",
      "    self._sslobj.do_handshake()\n",
      "TimeoutError: _ssl.c:989: The handshake operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/httpx/_transports/default.py\", line 67, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/httpx/_transports/default.py\", line 231, in handle_request\n",
      "    yield\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/httpx/_transports/default.py\", line 231, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py\", line 268, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py\", line 268, in handle_request\n",
      "    raise exc\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py\", line 251, in handle_request\n",
      "    raise exc\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py\", line 251, in handle_request\n",
      "    response = connection.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    response = connection.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    raise exc\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/httpcore/_sync/connection.py\", line 156, in _connect\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/httpcore/_sync/connection.py\", line 156, in _connect\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    stream = stream.start_tls(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/httpcore/_backends/sync.py\", line 152, in start_tls\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/contextlib.py\", line 158, in __exit__\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectTimeout: _ssl.c:989: The handshake operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectTimeout: _ssl.c:989: The handshake operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 761, in run_closure\n",
      "    self.run()\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 761, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/threading.py\", line 982, in run\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/gradio/analytics.py\", line 61, in _do_normal_analytics_request\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/gradio/analytics.py\", line 61, in _do_normal_analytics_request\n",
      "    data[\"ip_address\"] = get_local_ip_address()\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/gradio/analytics.py\", line 117, in get_local_ip_address\n",
      "    data[\"ip_address\"] = get_local_ip_address()\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/gradio/analytics.py\", line 117, in get_local_ip_address\n",
      "    ip_address = httpx.get(\n",
      "                 ^^^^^^^^^^\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/httpx/_api.py\", line 196, in get\n",
      "    ip_address = httpx.get(\n",
      "                 ^^^^^^^^^^\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/httpx/_api.py\", line 196, in get\n",
      "    return request(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/httpx/_api.py\", line 104, in request\n",
      "    return request(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/httpx/_api.py\", line 104, in request\n",
      "    return client.request(\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/httpx/_client.py\", line 828, in request\n",
      "    return client.request(\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/httpx/_client.py\", line 828, in request\n",
      "    return self.send(request, auth=auth, follow_redirects=follow_redirects)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/httpx/_client.py\", line 915, in send\n",
      "    return self.send(request, auth=auth, follow_redirects=follow_redirects)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/httpx/_client.py\", line 915, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/httpx/_client.py\", line 943, in _send_handling_auth\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/httpx/_client.py\", line 943, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/httpx/_client.py\", line 980, in _send_handling_redirects\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/httpx/_client.py\", line 980, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/httpx/_client.py\", line 1016, in _send_single_request\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/httpx/_client.py\", line 1016, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/httpx/_transports/default.py\", line 230, in handle_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/httpx/_transports/default.py\", line 230, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/contextlib.py\", line 158, in __exit__\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/httpx/_transports/default.py\", line 84, in map_httpcore_exceptions\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/Users/parakhchaudhary/opt/anaconda3/envs/chaenv/lib/python3.11/site-packages/httpx/_transports/default.py\", line 84, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectTimeout: _ssl.c:989: The handshake operation timed out\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectTimeout: _ssl.c:989: The handshake operation timed out\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# PDF Text Extraction Function\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    document = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(len(document)):\n",
    "        page = document[page_num]\n",
    "        text += page.get_text()\n",
    "    document.close()\n",
    "    return text.strip()\n",
    "\n",
    "# Monster API Client Configuration\n",
    "generation_model_name: str\n",
    "temperature: float = 0.9\n",
    "top_p = 0.9\n",
    "max_tokens: int = 2048\n",
    "stream: bool = False  # Set to False for simplicity in Gradio\n",
    "llm_name: str = \"Meta-Llama\"\n",
    "\n",
    "monster_client = OpenAI(\n",
    "    base_url=\"https://llm.monsterapi.ai/v1/\",\n",
    "    api_key=str(MONSTER_API_KEY)\n",
    ")\n",
    "\n",
    "monster_ai_model_name = {\n",
    "    \"Google-Gemma\": \"google/gemma-2-9b-it\",\n",
    "    \"Mistral\": \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    \"Microsoft-Phi\": \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    \"Meta-Llama\": \"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "}\n",
    "\n",
    "# Summarization Function\n",
    "def summarize_pdf(file):\n",
    "    try:\n",
    "        # Extract text from the uploaded PDF\n",
    "        pdf_text = extract_text_from_pdf(file.name)\n",
    "\n",
    "        # Create context for the AI summarization\n",
    "        message = [\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI assistant skilled in summarizing complex medical reports.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Summarize the following medical report in simple terms. Focus on the key findings, diagnoses, and recommendations. Report text:\\n\\n{pdf_text}\"}\n",
    "        ]\n",
    "\n",
    "        # Generate summary using Monster API\n",
    "        response = monster_client.chat.completions.create(\n",
    "            model=monster_ai_model_name[llm_name],\n",
    "            messages=message,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            max_tokens=max_tokens,\n",
    "            stream=False  # Simplify response handling\n",
    "        )\n",
    "\n",
    "        # Extract the summary from the response\n",
    "        generated_text = response.choices[0].message.content\n",
    "        return generated_text\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error occurred: {e}\"\n",
    "\n",
    "\n",
    "# Gradio Interface\n",
    "interface = gr.Interface(\n",
    "    fn=summarize_pdf,\n",
    "    inputs=gr.File(label=\"Upload your Medical Report (PDF)\"),\n",
    "    outputs=gr.Textbox(label=\"Generated Summary\"),\n",
    "    title=\"Medical Report Summarizer\",\n",
    "    description=\"Upload a medical report in PDF format, and this tool will generate a summary focusing on key findings, diagnoses, and recommendations.\"\n",
    ")\n",
    "\n",
    "# Launch the Interface\n",
    "interface.launch()\n",
    "\n",
    "response = monster_client.chat.completions.create(\n",
    "    model=monster_ai_model_name[llm_name],\n",
    "    messages=message,\n",
    "    temperature=temperature,\n",
    "    top_p=top_p,\n",
    "    max_tokens=max_tokens,\n",
    "    stream=stream\n",
    ")\n",
    "\n",
    "print(\"API Response:\", response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
